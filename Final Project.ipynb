{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a8eebc",
   "metadata": {},
   "source": [
    "## SRCNN\n",
    "\n",
    "We first implement a basic SRCNN model using tensorflow.\n",
    "References: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7bf79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    \"\"\"\n",
    "    Read h5 format data file\n",
    "    \n",
    "    Args:\n",
    "        path: file path of desired file\n",
    "        data: '.h5' file format that contains train data values\n",
    "        label: '.h5' file format that contains train label values\n",
    "    \"\"\"\n",
    "    with h5py.File(path, 'r') as hf:\n",
    "        data = np.array(hf.get('data'))\n",
    "        label = np.array(hf.get('label'))\n",
    "        return data, label\n",
    "\n",
    "def preprocess(path, scale=3):\n",
    "    \"\"\"\n",
    "    Preprocess single image file \n",
    "        (1) Read original image as YCbCr format (and grayscale as default)\n",
    "        (2) Normalize\n",
    "        (3) Apply image file with bicubic interpolation\n",
    "    Args:\n",
    "        path: file path of desired file\n",
    "        input_: image applied bicubic interpolation (low-resolution)\n",
    "        label_: image with original resolution (high-resolution)\n",
    "    \"\"\"\n",
    "    image = imread(path, is_grayscale=True)\n",
    "    label_ = modcrop(image, scale)\n",
    "\n",
    "    # Must be normalized\n",
    "    image = image / 255.\n",
    "    label_ = label_ / 255.\n",
    "\n",
    "    input_ = scipy.ndimage.interpolation.zoom(label_, (1./scale), prefilter=False)\n",
    "    input_ = scipy.ndimage.interpolation.zoom(input_, (scale/1.), prefilter=False)\n",
    "\n",
    "    return input_, label_\n",
    "\n",
    "def prepare_data(sess, dataset, is_train):\n",
    "    if is_train:\n",
    "        filenames = os.listdir(dataset)\n",
    "        data_dir = os.path.join(os.getcwd(), dataset)\n",
    "        data = glob.glob(os.path.join(data_dir, \"*.bmp\"))\n",
    "    else:\n",
    "        data_dir = os.path.join(os.sep, (os.path.join(os.getcwd(), dataset)), \"Set5\")\n",
    "        data = glob.glob(os.path.join(data_dir, \"*.bmp\"))\n",
    "\n",
    "    return data\n",
    "\n",
    "def make_data(sess, data, label, is_train):\n",
    "    if is_train:\n",
    "        savepath = os.path.join(os.getcwd(), 'checkpoint/train.h5')\n",
    "    else:\n",
    "        savepath = os.path.join(os.getcwd(), 'checkpoint/test.h5')\n",
    "\n",
    "    with h5py.File(savepath, 'w') as hf:\n",
    "        hf.create_dataset('data', data=data)\n",
    "        hf.create_dataset('label', data=label)\n",
    "\n",
    "def rgb2ycbcr(im):\n",
    "    xform = np.array([[.299, .587, .114], [-.1687, -.3313, .5], [.5, -.4187, -.0813]])\n",
    "    ycbcr = im.dot(xform.T)\n",
    "    ycbcr[:,:,[1,2]] += 128\n",
    "    return np.uint8(ycbcr)\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def imread(path, is_grayscale=True):\n",
    "    if is_grayscale:\n",
    "        return rgb2gray(rgb2ycbcr(imageio.imread(path).astype(np.float)))\n",
    "    else:\n",
    "        return rgb2ycbcr(imageio.imread(path).astype(np.float))\n",
    "\n",
    "def modcrop(image, scale=3):\n",
    "    if len(image.shape) == 3:\n",
    "        h, w, _ = image.shape\n",
    "        h = h - np.mod(h, scale)\n",
    "        w = w - np.mod(w, scale)\n",
    "        image = image[0:h, 0:w, :]\n",
    "    else:\n",
    "        h, w = image.shape\n",
    "        h = h - np.mod(h, scale)\n",
    "        w = w - np.mod(w, scale)\n",
    "        image = image[0:h, 0:w]\n",
    "    return image\n",
    "\n",
    "def input_setup(sess, config):\n",
    "    # Load data path\n",
    "    if config.is_train:\n",
    "        data = prepare_data(sess, dataset=\"Train\", is_train=True)\n",
    "    else:\n",
    "        data = prepare_data(sess, dataset=\"Test\", is_train=False)\n",
    "\n",
    "    sub_input_sequence = []\n",
    "    sub_label_sequence = []\n",
    "    padding = abs(config.image_size - config.label_size) / 2 # 6\n",
    "\n",
    "    if config.is_train:\n",
    "        for i in range(len(data)):\n",
    "            input_, label_ = preprocess(data[i], config.scale)\n",
    "\n",
    "            if len(input_.shape) == 3:\n",
    "                h, w, _ = input_.shape\n",
    "            else:\n",
    "                h, w = input_.shape\n",
    "\n",
    "            for x in range(0, h-config.image_size+1, config.stride):\n",
    "                for y in range(0, w-config.image_size+1, config.stride):\n",
    "                    sub_input = input_[x:x+config.image_size, y:y+config.image_size] # [33 x 33]\n",
    "                    sub_label = label_[x+int(padding):x+int(padding)+config.label_size, y+int(padding):y+int(padding)+config.label_size] # [21 x 21]\n",
    "\n",
    "                    # Make channel value\n",
    "                    sub_input = sub_input.reshape([config.image_size, config.image_size, 1])  \n",
    "                    sub_label = sub_label.reshape([config.label_size, config.label_size, 1])\n",
    "\n",
    "                    sub_input_sequence.append(sub_input)\n",
    "                    sub_label_sequence.append(sub_label)\n",
    "\n",
    "    else:\n",
    "        input_, label_ = preprocess(data[2], config.scale)\n",
    "\n",
    "        if len(input_.shape) == 3:\n",
    "            h, w, _ = input_.shape\n",
    "        else:\n",
    "            h, w = input_.shape\n",
    "\n",
    "        # Numbers of sub-images in height and width of image are needed to compute merge operation.\n",
    "        nx = ny = 0 \n",
    "        for x in range(0, h-config.image_size+1, config.stride):\n",
    "            nx += 1; ny = 0\n",
    "            for y in range(0, w-config.image_size+1, config.stride):\n",
    "                ny += 1\n",
    "                sub_input = input_[x:x+config.image_size, y:y+config.image_size] # [33 x 33]\n",
    "                sub_label = label_[x+int(padding):x+int(padding)+config.label_size, y+int(padding):y+int(padding)+config.label_size] # [21 x 21]\n",
    "                \n",
    "                sub_input = sub_input.reshape([config.image_size, config.image_size, 1])  \n",
    "                sub_label = sub_label.reshape([config.label_size, config.label_size, 1])\n",
    "\n",
    "                sub_input_sequence.append(sub_input)\n",
    "                sub_label_sequence.append(sub_label)\n",
    "\n",
    "    \"\"\"\n",
    "    len(sub_input_sequence) : the number of sub_input (33 x 33 x ch) in one image\n",
    "    (sub_input_sequence[0]).shape : (33, 33, 1)\n",
    "    \"\"\"\n",
    "    # Make list to numpy array. With this transform\n",
    "    arrdata = np.asarray(sub_input_sequence) # [?, 33, 33, 1]\n",
    "    arrlabel = np.asarray(sub_label_sequence) # [?, 21, 21, 1]\n",
    "\n",
    "    make_data(sess, arrdata, arrlabel, config.is_train)\n",
    "\n",
    "    if not config.is_train:\n",
    "        return nx, ny\n",
    "        \n",
    "def imsave(image, path):\n",
    "    return scipy.misc.imsave(path, image)\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h*size[0], w*size[1], 1))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca259c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    xrange\n",
    "except:\n",
    "    xrange = range\n",
    "\n",
    "class SRCNN(object):\n",
    "\n",
    "    def __init__(self, sess, image_size=33,label_size=21, batch_size=128,c_dim=1, checkpoint_dir=None, sample_dir=None, is_train=True):\n",
    "\n",
    "        self.sess = sess\n",
    "        self.is_grayscale = (c_dim == 1)\n",
    "        self.image_size = image_size\n",
    "        self.label_size = label_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.c_dim = c_dim\n",
    "\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.sample_dir = sample_dir\n",
    "        self.is_train = is_train\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.images = tf.placeholder(tf.float32, [None, self.image_size, self.image_size, self.c_dim], name='images')\n",
    "        self.labels = tf.placeholder(tf.float32, [None, self.label_size, self.label_size, self.c_dim], name='labels')\n",
    "        \n",
    "        self.weights = {\n",
    "            'w1': tf.Variable(tf.random_normal([9, 9, 1, 64], stddev=1e-3), name='w1'),\n",
    "            'w2': tf.Variable(tf.random_normal([1, 1, 64, 32], stddev=1e-3), name='w2'),\n",
    "            'w3': tf.Variable(tf.random_normal([5, 5, 32, 1], stddev=1e-3), name='w3')\n",
    "        }\n",
    "        self.biases = {\n",
    "            'b1': tf.Variable(tf.zeros([64]), name='b1'),\n",
    "            'b2': tf.Variable(tf.zeros([32]), name='b2'),\n",
    "            'b3': tf.Variable(tf.zeros([1]), name='b3')\n",
    "        }\n",
    "\n",
    "        self.pred = self.model()\n",
    "\n",
    "        # Loss function (MSE)\n",
    "        self.loss = tf.reduce_mean(tf.square(self.labels - self.pred))\n",
    "\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "    def train(self, config):\n",
    "        if config.is_train:\n",
    "            input_setup(self.sess, config)\n",
    "        else:\n",
    "            nx, ny = input_setup(self.sess, config)\n",
    "\n",
    "        if config.is_train:     \n",
    "            data_dir = os.path.join('./{}'.format(config.checkpoint_dir), \"train.h5\")\n",
    "        else:\n",
    "            data_dir = os.path.join('./{}'.format(config.checkpoint_dir), \"test.h5\")\n",
    "\n",
    "        train_data, train_label = read_data(data_dir)\n",
    "\n",
    "        # Stochastic gradient descent with the standard backpropagation\n",
    "        self.train_op = tf.train.GradientDescentOptimizer(config.learning_rate).minimize(self.loss)\n",
    "\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        counter = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        if self.load(self.checkpoint_dir):\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "        else:\n",
    "            print(\" [!] Load failed...\")\n",
    "\n",
    "        if config.is_train:\n",
    "            print(\"Training...\")\n",
    "\n",
    "            for ep in xrange(config.epoch):\n",
    "                # Run by batch images\n",
    "                batch_idxs = len(train_data) // config.batch_size\n",
    "                for idx in xrange(0, batch_idxs):\n",
    "                    batch_images = train_data[idx*config.batch_size : (idx+1)*config.batch_size]\n",
    "                    batch_labels = train_label[idx*config.batch_size : (idx+1)*config.batch_size]\n",
    "\n",
    "                    counter += 1\n",
    "                    _, err = self.sess.run([self.train_op, self.loss], feed_dict={self.images: batch_images, self.labels: batch_labels})\n",
    "\n",
    "                    if counter % 10 == 0:\n",
    "                        print(\"Epoch: [%2d], step: [%2d], time: [%4.4f], loss: [%.8f]\" \\\n",
    "                            % ((ep+1), counter, time.time()-start_time, err))\n",
    "\n",
    "                    if counter % 500 == 0:\n",
    "                        self.save(config.checkpoint_dir, counter)\n",
    "\n",
    "        else:\n",
    "            print(\"Testing...\")\n",
    "\n",
    "            result = self.pred.eval({self.images: train_data, self.labels: train_label})\n",
    "\n",
    "            result = merge(result, [nx, ny])\n",
    "            result = result.squeeze()\n",
    "            image_path = os.path.join(os.getcwd(), config.sample_dir)\n",
    "            image_path = os.path.join(image_path, \"test_image.png\")\n",
    "            imsave(result, image_path)\n",
    "\n",
    "    def model(self):\n",
    "        conv1 = tf.nn.relu(tf.nn.conv2d(self.images, self.weights['w1'], strides=[1,1,1,1], padding='VALID') + self.biases['b1'])\n",
    "        conv2 = tf.nn.relu(tf.nn.conv2d(conv1, self.weights['w2'], strides=[1,1,1,1], padding='VALID') + self.biases['b2'])\n",
    "        conv3 = tf.nn.conv2d(conv2, self.weights['w3'], strides=[1,1,1,1], padding='VALID') + self.biases['b3']\n",
    "        return conv3\n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        model_name = \"SRCNN.model\"\n",
    "        model_dir = \"%s_%s\" % (\"srcnn\", self.label_size)\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,\n",
    "                                        os.path.join(checkpoint_dir, model_name),\n",
    "                                        global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        model_dir = \"%s_%s\" % (\"srcnn\", self.label_size)\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "                ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "                self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "                return True\n",
    "        else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bba8074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/humanoid/o-conda/anaconda3/envs/tf1.x/lib/python3.7/site-packages/ipykernel_launcher.py:85: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_3649226/2836084610.py:66: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/humanoid/o-conda/anaconda3/envs/tf1.x/lib/python3.7/site-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      " [*] Reading checkpoints...\n",
      " [!] Load failed...\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3654859 thread 1 bound to OS proc set 1\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655481 thread 2 bound to OS proc set 2\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655482 thread 3 bound to OS proc set 3\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655483 thread 4 bound to OS proc set 4\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655484 thread 5 bound to OS proc set 5\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655485 thread 6 bound to OS proc set 6\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655486 thread 7 bound to OS proc set 7\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655487 thread 8 bound to OS proc set 8\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655488 thread 9 bound to OS proc set 9\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655489 thread 10 bound to OS proc set 10\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655490 thread 11 bound to OS proc set 11\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655491 thread 12 bound to OS proc set 12\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655492 thread 13 bound to OS proc set 13\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655493 thread 14 bound to OS proc set 14\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655494 thread 15 bound to OS proc set 15\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655496 thread 17 bound to OS proc set 17\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655495 thread 16 bound to OS proc set 16\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655497 thread 18 bound to OS proc set 18\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655498 thread 19 bound to OS proc set 19\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655499 thread 20 bound to OS proc set 20\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655500 thread 21 bound to OS proc set 21\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655501 thread 22 bound to OS proc set 22\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655502 thread 23 bound to OS proc set 23\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655503 thread 24 bound to OS proc set 24\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655504 thread 25 bound to OS proc set 25\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655505 thread 26 bound to OS proc set 26\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655506 thread 27 bound to OS proc set 27\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655507 thread 28 bound to OS proc set 28\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655508 thread 29 bound to OS proc set 29\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655509 thread 30 bound to OS proc set 30\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655510 thread 31 bound to OS proc set 31\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655511 thread 32 bound to OS proc set 0\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3654860 thread 33 bound to OS proc set 1\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655512 thread 34 bound to OS proc set 2\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655513 thread 35 bound to OS proc set 3\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655514 thread 36 bound to OS proc set 4\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655515 thread 37 bound to OS proc set 5\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655516 thread 38 bound to OS proc set 6\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655517 thread 39 bound to OS proc set 7\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655518 thread 40 bound to OS proc set 8\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655519 thread 41 bound to OS proc set 9\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655520 thread 42 bound to OS proc set 10\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655521 thread 43 bound to OS proc set 11\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655522 thread 44 bound to OS proc set 12\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655523 thread 45 bound to OS proc set 13\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655524 thread 46 bound to OS proc set 14\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655525 thread 47 bound to OS proc set 15\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655526 thread 48 bound to OS proc set 16\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655527 thread 49 bound to OS proc set 17\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655528 thread 50 bound to OS proc set 18\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655529 thread 51 bound to OS proc set 19\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655530 thread 52 bound to OS proc set 20\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655531 thread 53 bound to OS proc set 21\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655532 thread 54 bound to OS proc set 22\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655533 thread 55 bound to OS proc set 23\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655534 thread 56 bound to OS proc set 24\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655535 thread 57 bound to OS proc set 25\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655536 thread 58 bound to OS proc set 26\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655537 thread 59 bound to OS proc set 27\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655538 thread 60 bound to OS proc set 28\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655540 thread 62 bound to OS proc set 30\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655541 thread 63 bound to OS proc set 31\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655542 thread 64 bound to OS proc set 0\n",
      "OMP: Info #254: KMP_AFFINITY: pid 3649226 tid 3655539 thread 61 bound to OS proc set 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1], step: [10], time: [1.1690], loss: [0.20777231]\n",
      "Epoch: [ 1], step: [20], time: [2.1012], loss: [0.37647262]\n",
      "Epoch: [ 1], step: [30], time: [2.9614], loss: [0.26794398]\n",
      "Epoch: [ 1], step: [40], time: [3.8149], loss: [0.20024158]\n",
      "Epoch: [ 1], step: [50], time: [4.7067], loss: [0.18675004]\n",
      "Epoch: [ 1], step: [60], time: [5.6031], loss: [0.21128026]\n",
      "Epoch: [ 1], step: [70], time: [6.4764], loss: [0.30240336]\n",
      "Epoch: [ 1], step: [80], time: [7.3751], loss: [0.22678497]\n",
      "Epoch: [ 1], step: [90], time: [8.2590], loss: [0.17680673]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3649226/3870590280.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0msrcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"checkpoint\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sample\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0msrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3649226/2836084610.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf1.x/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf1.x/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf1.x/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf1.x/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf1.x/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf1.x/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "class config_c:\n",
    "    def __init__(self):\n",
    "        self.epoch=15000\n",
    "        self.batch_size=128\n",
    "        self.image_size=33\n",
    "        self.label_size=21\n",
    "        self.learning_rate=1e-4\n",
    "        self.c_dim=1\n",
    "        self.scale=3\n",
    "        self.stride=14\n",
    "        self.checkpoint_dir=\"checkpoint\"\n",
    "        self.sample_dir=\"sample\"\n",
    "        self.is_train=True\n",
    "\n",
    "config=config_c()\n",
    "\n",
    "if not os.path.exists(config.checkpoint_dir):\n",
    "    os.makedirs(config.checkpoint_dir)\n",
    "if not os.path.exists(config.sample_dir):\n",
    "    os.makedirs(config.sample_dir)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    srcnn = SRCNN(sess,image_size=33,label_size=21,batch_size=128,c_dim=1,checkpoint_dir=\"checkpoint\",sample_dir=\"sample\",is_train=True)\n",
    "\n",
    "    srcnn.train(config)\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabdca40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.x",
   "language": "python",
   "name": "tf1.x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
